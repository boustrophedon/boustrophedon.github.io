Date: 2018-10-17
Status: Draft

[This talk, by Gunter Stein, from 1989 at an IEEE conference on control systems](https://www.youtube.com/watch?v=9Lhu31X94V4) is *extremely* interesting for a myriad of reasons. Much of the technical stuff about control systems, [Bode integrals](https://en.wikipedia.org/wiki/Bode%27s_sensitivity_integral), [Nyquist diagrams](https://en.wikipedia.org/wiki/Nyquist_stability_criterion#Nyquist_plot) I didn't really fully understand since I don't have the background and didn't know some of the terms and jargon, but yet I was still able to take away a lot from the talk.

Although there are many interesting things to talk about, the overall thesis for the talk is that, you need to undestand the fundamentals, the theoretical bases and ethics (in terms of professional ethics), in order to use the tools we have, and understand their output, particularly in control systems where huge losses can occur when they fail. His two main case studies, two unstable (in a technical sense) control systems in experimental aircraft and in the Chernobyl nuclear reactor, were both bookended with points about *overall* system design.

In the first example, his point was more about trying to design a control system to fit some parameters without first trying to determine if it was possible to do so. That is, trying to use the tools without thinking, "Are these tools the correct tools to use? Will they work given our constraints?".

In the second, the system was designed such that it shouldn't be run in a specific state for an extended period of time, or the system became unstable. But, it had to pass through that unstable state to reach a stable state. During an unrelated test, the reactor was put in the bad state manually by the operators, who either ignored or didn't know that it should not be kept there. The problem was that fundamentally, it shouldn't have been possible to manually keep it in the bad state, given that the designers knew it would have been bad to do so. 


There was an article (or maybe it was a talk) somewhere that I read once that drew various line graphs representing your understanding of a mathematical talk, or perhaps the difficulty of the material presented, over time. A typical math talk looks like an exponential graph: It starts with some basic opening remarks and then very quickly gets technical and you lose most of your audience. This talk was much more like the good talks: like a gentle hill, it starts easy, gets harder, and then eases off at the end. If the talk covers multiple topics, it has multiple hills. This talk is very representative of that difficulty curve.

Control theory is a subject that has somewhat fallen out of favor, yet holds deep, practical engineering insights founded on solid mathematics. In contrast, software development shares many goals of control systems (and indeed many control systems are implemented using software) but is seriously lacking in any sort of formal mathematical backing in many cases. Additionally, control theorists and control engineers are educated very differently: Stein emphasizes right at the beginning the importance that engineers keep in mind the dangers related to the systems they create.


There's also, in one slide, command line input to some sort of control systems synthesis software ([apparently to solve an h-infinity problem](https://en.wikipedia.org/wiki/H-infinity_methods_in_control_theory)) from the 80's that I'm unfamiliar with, and he mentions various others software systems that automatically generate code from control system constraints and link it in to programs controlling actual hardware and such. Combined with some of the stuff I'm reading from The Mythical Man-Month, it seems to me that in general older software systems were much more holistic. Modern systems somehow have the worst of both worlds: every system is slightly different with millions of little dials and knobs to configure, and yet the web and javascript "webapps" are centralizing everything but it's still a mess, and it's not even properly holistically centralized because all your data is in separate little silos and stuck inside your mobile phone and everything's awful!

Anyone who watches this talk probably has the same favorite part: he presents a very simple, understandable problem with a physical demonstration (the inverted pendulum problem: why is it more difficult to control as the pendulum gets shorter), then proceeds to talk about math and seemingly-unrelated topics in control systems, and then presents a solution to the original problem using the tools he laid out previously in the talk. Incidentally, when I tried to come up with a reason for why it's difficult to control an inverted pendulum, my thinking was that as the pendulum gets shorter, you have less time to react before it falls out of control: the required latency is lower. Stein's solution was in terms of bandwith, and my friend helped convince me that bandwidth is the most important factor.

Additionally, this talk is super interesting because it is done entirely on a transparency projector, and yet strongly reminds me of the very best modern powerpoint presentations I've seen, talks by e.g. Gary Bernhardt, Scott Meyers, Bret Victor, even Steve Jobs. I would love to learn how to give presentations like those: Concise, often funny, with minimal words and strongly evocative imagery and prose. The best talks impart ideas to you not just via the substance but also the style. I have a feeling there's probably something by Donald Norman on presentations but otherwise I don't know where to begin to learn how to do so.


The above two points are actually deeply related: *Adding constraints can lead to improved results*. This is a pretty universally-acknowledged idea, but I thought I'd write about it a bit since it came up multiple times.
